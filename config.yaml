model:
  name: "mobilenet_detection"
  backbone: "mobilenet_v3_small"
  num_classes: 2  # Background (0) and tick (1)
  pretrained: true
  freeze_backbone: false  # Don't freeze since we're doing training
  min_size: 512  # Reduced for mobile efficiency
  max_size: 512  # Reduced for mobile efficiency
  box_score_thresh: 0.5
  box_nms_thresh: 0.3
  box_detections_per_img: 50  # Reduced for mobile efficiency
  anchor_sizes: [16, 32, 64, 128]  # Simplified anchor sizes
  anchor_ratios: [0.5, 1.0, 2.0]  # Standard anchor ratios

data:
  train_paths:  # Updated to use multiple chunks
    - "data/chunk_001/images"
    - "data/chunk_002/images"
    - "data/chunk_003/images"
    - "data/chunk_004/images"
    - "data/chunk_005/images"
    - "data/chunk_006/images"
    - "data/chunk_007/images"
  train_annotations:  # Updated to use multiple annotation files
    - "data/chunk_001/annotations.json"
    - "data/chunk_002/annotations.json"
    - "data/chunk_003/annotations.json"
    - "data/chunk_004/annotations.json"
    - "data/chunk_005/annotations.json"
    - "data/chunk_006/annotations.json"
    - "data/chunk_007/annotations.json"
  val_split: 0.2
  input_size: [512, 512]  # Reduced for mobile efficiency
  mean: [0.6267567782543599, 0.5714833621501922, 0.5203172379808501]  # Computed from dataset
  std: [0.15882498020157218, 0.16065719380769877, 0.1602449702085927]  # Computed from dataset
  categories:  # Updated to be consistent with num_classes
    - id: 0
      name: "background"
    - id: 1
      name: "tick"

training:
  # Basic training parameters
  device: "cuda"  # Moved from model section
  num_epochs: 100          # Increased from 50
  batch_size: 7           # Reduced from 7 to lower VRAM usage
  learning_rate: 0.0001   # Increased from 0.00001 to a more appropriate value for RetinaNet
  weight_decay: 0.001     # Increased from 0.0001 for stronger regularization
  
  # Early stopping parameters
  min_epochs: 20          # Reduced from 30 since we see divergence earlier
  early_stopping_patience: 5  # Reduced from 10 to stop earlier when validation loss increases
  
  # Learning rate scheduling
  lr_scheduler:
    name: "reduce_on_plateau"
    factor: 0.2           # More aggressive LR reduction (was 0.5)
    patience: 5           # Reduced from 8 to reduce LR more frequently
    min_lr: 0.00001       # Increased from 0.000001 to maintain higher minimum learning rate
  
  # Data loading
  num_workers: 4  # Reduced from 12 to minimize multiprocessing issues
  pin_memory: true
  prefetch_factor: 2
  persistent_workers: false  # Disabled to reduce multiprocessing complexity
  
  # Mixed precision training
  use_amp: true  # Renamed from mixed_precision to match code
  channels_last: true     # Memory format optimization
  
  # CUDA optimizations
  allow_tf32: true

output:
  checkpoint_dir: "outputs/training/checkpoints"
  output_dir: "outputs"
  training_curves: "outputs/training/curves"
  evaluation_dir: "outputs/evaluation"

augmentation:
  train:
    horizontal_flip: true
    vertical_flip: true
    rotate:
      enabled: true
      limit: 45
    scale:
      enabled: true
      min: 0.8
      max: 1.2
    brightness:
      enabled: true
      limit: 0.2
    contrast:
      enabled: true
      limit: 0.2
    blur:
      enabled: true
      limit: 3
    noise:
      enabled: true
      limit: 0.05
  
  val:
    resize_only: true

classes:
  # Updated to be consistent with num_classes
  0: "background"
  1: "tick"

paths:
  checkpoint_dir: "checkpoints"
  output_dir: "outputs" 
